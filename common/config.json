{
    "model": {
        "batch-size": 16,
        "max-length-tokens": 300,
        "random-seed": 42,
        "n-classes": 2,
        "epochs": 5
    }
}